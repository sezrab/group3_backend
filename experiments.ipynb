{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import topic_classifier.paper_processor as pp\n",
    "import topic_classifier.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model (50/50)\n",
      "analysis (40/50)\n",
      "language (49/50)\n",
      "dataset (50/50)\n",
      "task (49/50)\n",
      "data (50/50)\n",
      "text (48/50)\n",
      "method (50/50)\n",
      "performance (49/50)\n",
      "llm (38/50)\n",
      "paper (49/50)\n",
      "result (46/50)\n",
      "various (33/50)\n",
      "study (47/50)\n",
      "research (45/50)\n",
      "new (45/50)\n",
      "based (45/50)\n",
      "information (47/50)\n",
      "technique (33/50)\n",
      "large (45/50)\n",
      "understand (32/50)\n",
      "approach (50/50)\n",
      "different (47/50)\n",
      "process (47/50)\n",
      "propose (49/50)\n",
      "present (42/50)\n",
      "train (43/50)\n",
      "provide (39/50)\n",
      "us (36/50)\n",
      "use (42/50)\n",
      "feature (31/50)\n",
      "system (47/50)\n",
      "domain (34/50)\n",
      "evaluation (31/50)\n",
      "experiment (35/50)\n",
      "challenge (45/50)\n",
      "demonstrate (38/50)\n",
      "aim (31/50)\n",
      "proposed (36/50)\n",
      "two (41/50)\n",
      "work (50/50)\n",
      "application (31/50)\n",
      "learn (43/50)\n",
      "framework (43/50)\n",
      "address (31/50)\n",
      "human (31/50)\n",
      "stateoftheart (32/50)\n",
      "introduce (31/50)\n",
      "novel (41/50)\n"
     ]
    }
   ],
   "source": [
    "# The following code is used to identify stop words specific to a given dataset.\n",
    "\n",
    "vf = utils.load_topic_vector_file(folder='topic_classifier/data')\n",
    "\n",
    "common_word_counter = {}\n",
    "\n",
    "total = len(vf.keys())\n",
    "\n",
    "for topic in vf.keys():\n",
    "    # print the top 10 words for each topic\n",
    "    # vf[topic] is a dictionary of words and their weights.\n",
    "        \n",
    "    # sort the words by their weights\n",
    "    words = sorted(vf[topic].items(), key=lambda x: x[1], reverse=True)\n",
    "    n_words = len(words)\n",
    "\n",
    "    stop_potential = int(0.4 * n_words)\n",
    "\n",
    "    for word, weight in words[:stop_potential]:\n",
    "        if word in common_word_counter:\n",
    "            common_word_counter[word] += 1\n",
    "        else:\n",
    "            common_word_counter[word] = 1\n",
    "    \n",
    "for word, count in common_word_counter.items():\n",
    "    if count > 0.6 * total:\n",
    "        print(word, f'({count}/{total})')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
